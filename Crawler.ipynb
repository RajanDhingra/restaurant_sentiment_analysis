{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for scarping of Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train= pd.read_csv('C:\\\\Users\\\\Rajan\\\\Documents\\\\Lab\\\\Sentiment\\\\Final Folder\\\\data\\\\train_links.csv')\n",
    "test=  pd.read_csv('C:\\\\Users\\\\Rajan\\\\Documents\\\\Lab\\\\Sentiment\\\\Final Folder\\\\data\\\\test_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Train Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Crystal Jade</td>\n",
       "      <td>89</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>London Fat Duck</td>\n",
       "      <td>147</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>LONG BEACH @ DEMPSEY</td>\n",
       "      <td>419</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Peach Blossoms (Marina Mandarin)</td>\n",
       "      <td>308</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Yum Cha Restaurant</td>\n",
       "      <td>339</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                              name  reviews  \\\n",
       "0  Chinese                      Crystal Jade       89   \n",
       "1  Chinese                   London Fat Duck      147   \n",
       "2  Chinese              LONG BEACH @ DEMPSEY      419   \n",
       "3  Chinese  Peach Blossoms (Marina Mandarin)      308   \n",
       "4  Chinese                Yum Cha Restaurant      339   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = train['link'].tolist()\n",
    "Name= train.name.tolist()\n",
    "shares= train.reviews.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring pages scraping in python; each page got 10 reviews, so a restaurant with 100 reviews will have 10 pages, so we need to generate a list of URL's depending on the review count of the restaurant. For changing the page number, trip advisor change the URL by adding a set of characters between Reviews and Restaruant name. <br>\n",
    "e.g. <br> https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d8277271-Reviews-Angelina_MBS-Singapore.html <br> changes to <br> https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d8277271-Reviews-or10-Angelina_MBS-Singapore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for z in links:\n",
    "k=0\n",
    "url=[]\n",
    "for i in shares:\n",
    "    url.append(links[k])\n",
    "    for j in range(10,i,10):\n",
    "        url.append(links[k].replace('Reviews', 'Reviews-or'+str(j)))\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "review_body=[]\n",
    "review_date=[]\n",
    "reviewer_name=[]\n",
    "bubble_rating=[]\n",
    "item_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7195162-Reviews-Crystal_Jade_Palace-Singapore.html\n",
      "clicked first page...\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=69.0.3497.100)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-77074afbadb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clicked first page...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \"\"\"\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    322\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=69.0.3497.100)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n"
     ]
    }
   ],
   "source": [
    "drive=webdriver.Chrome(\"C:\\\\Users\\\\Rajan\\\\Documents\\\\Lab\\\\chromedriver.exe\")\n",
    "drive.set_page_load_timeout(10)\n",
    "j=0\n",
    "\n",
    "for i in range(0,len(url)):\n",
    "    print(url[j])\n",
    "    drive.get(url[j])\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        el = drive.find_element_by_class_name(\"ulBlueLinks\")\n",
    "        el.click()\n",
    "    except:\n",
    "        print('Page was not loaded')\n",
    "    print(\"clicked first page...\")\n",
    "    time.sleep(10)\n",
    "    data = drive.page_source\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    i=1\n",
    "    \n",
    "    for link in soup.find_all(\"div\", {\"class\":\"review-container\"}):\n",
    "        item_name.append(name[j])\n",
    "        title.append(link.find('span', class_='noQuotes').text)\n",
    "        review_body.append(link.find('p', class_='partial_entry').text)\n",
    "        review_date.append(link.find('span', class_='relativeDate')['title'])\n",
    "        reviewer_name.append(link.find('span', class_='scrname').text)\n",
    "        bubble_rating.append(link.select_one('div.reviewItemInline span.ui_bubble_rating')['class'][1][7:])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked first page...\n"
     ]
    }
   ],
   "source": [
    "drive=webdriver.Chrome(\"C:\\\\Users\\\\Rajan\\\\Documents\\\\Lab\\\\chromedriver.exe\")\n",
    "drive.set_page_load_timeout(10)\n",
    "results=[]\n",
    "title=[]\n",
    "review_body=[]\n",
    "review_date=[]\n",
    "reviewer_name=[]\n",
    "bubble_rating=[]\n",
    "drive.get(\"https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d8277271-Reviews-Angelina_MBS-Singapore.html\")\n",
    "#drive.maximize_window()\n",
    "#time.sleep(10)\n",
    "\n",
    "el = drive.find_element_by_class_name(\"ulBlueLinks\")\n",
    "el.click()\n",
    "\n",
    "print(\"clicked first page...\")\n",
    "\n",
    "time.sleep(2)\n",
    "data = drive.page_source\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "i=1\n",
    "for link in soup.find_all(\"div\", {\"class\":\"review-container\"}):\n",
    "    title.append(link.find('span', class_='noQuotes').text)\n",
    "    review_body.append(link.find('p', class_='partial_entry').text)\n",
    "    review_date.append(link.find('span', class_='relativeDate')['title'])\n",
    "    reviewer_name.append(link.find('span', class_='scrname').text)\n",
    "    bubble_rating.append(link.select_one('div.reviewItemInline span.ui_bubble_rating')['class'][1][7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(list(zip(item_name,title, review_body, review_date, reviewer_name, bubble_rating)))\n",
    "df.columns = ['Restaurant_Name','Review_Title', 'Review_Content', 'Review_Date' ,'Reviewer_Name', 'Rating']\n",
    "df.to_excel('\\\\data\\\\Trainset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('\\\\data\\\\Trainset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japnese</td>\n",
       "      <td>Din Tai Fung</td>\n",
       "      <td>149</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japnese</td>\n",
       "      <td>Mitzo</td>\n",
       "      <td>556</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japnese</td>\n",
       "      <td>Summer Pavilion</td>\n",
       "      <td>370</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>Antoinette</td>\n",
       "      <td>162</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>L_Entrecote_the_French_Brasserie</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                              name  reviews  \\\n",
       "0  Japnese                      Din Tai Fung      149   \n",
       "1  Japnese                             Mitzo      556   \n",
       "2  Japnese                   Summer Pavilion      370   \n",
       "3   French                        Antoinette      162   \n",
       "4   French  L_Entrecote_the_French_Brasserie       20   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = train['link'].tolist()\n",
    "Name= train.name.tolist()\n",
    "shares= train.reviews.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring pages scraping in python; each page got 10 reviews, so a restaurant with 100 reviews will have 10 pages, so we need to generate a list of URL's depending on the review count of the restaurant. For changing the page number, trip advisor change the URL by adding a set of characters between Reviews and Restaruant name. <br>\n",
    "e.g. <br> https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d8277271-Reviews-Angelina_MBS-Singapore.html <br> changes to <br> https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d8277271-Reviews-or10-Angelina_MBS-Singapore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for z in links:\n",
    "k=0\n",
    "url=[]\n",
    "for i in shares:\n",
    "    url.append(links[k])\n",
    "    for j in range(10,i,10):\n",
    "        url.append(links[k].replace('Reviews', 'Reviews-or'+str(j)))\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "review_body=[]\n",
    "review_date=[]\n",
    "reviewer_name=[]\n",
    "bubble_rating=[]\n",
    "item_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7195162-Reviews-Crystal_Jade_Palace-Singapore.html\n",
      "clicked first page...\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=69.0.3497.100)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-77074afbadb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clicked first page...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \"\"\"\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    322\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=69.0.3497.100)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n"
     ]
    }
   ],
   "source": [
    "drive=webdriver.Chrome(\"C:\\\\Users\\\\Rajan\\\\Documents\\\\Lab\\\\chromedriver.exe\")\n",
    "drive.set_page_load_timeout(10)\n",
    "j=0\n",
    "\n",
    "for i in range(0,len(url)):\n",
    "    print(url[j])\n",
    "    drive.get(url[j])\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        el = drive.find_element_by_class_name(\"ulBlueLinks\")\n",
    "        el.click()\n",
    "    except:\n",
    "        print('Page was not loaded')\n",
    "    print(\"clicked first page...\")\n",
    "    time.sleep(10)\n",
    "    data = drive.page_source\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    i=1\n",
    "    \n",
    "    for link in soup.find_all(\"div\", {\"class\":\"review-container\"}):\n",
    "        item_name.append(name[j])\n",
    "        title.append(link.find('span', class_='noQuotes').text)\n",
    "        review_body.append(link.find('p', class_='partial_entry').text)\n",
    "        review_date.append(link.find('span', class_='relativeDate')['title'])\n",
    "        reviewer_name.append(link.find('span', class_='scrname').text)\n",
    "        bubble_rating.append(link.select_one('div.reviewItemInline span.ui_bubble_rating')['class'][1][7:])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(list(zip(item_name,title, review_body, review_date, reviewer_name, bubble_rating)))\n",
    "df.columns = ['Restaurant_Name','Review_Title', 'Review_Content', 'Review_Date' ,'Reviewer_Name', 'Rating']\n",
    "\n",
    "df.to_csv('\\\\data\\\\Trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>bubble_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antoinette</td>\n",
       "      <td>Superb Service</td>\n",
       "      <td>The staff @ Mandarin Gallery are very friendly...</td>\n",
       "      <td>18 October 2018</td>\n",
       "      <td>blueyme</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antoinette</td>\n",
       "      <td>Perfect high tea place</td>\n",
       "      <td>Not my first visit and I believe the service h...</td>\n",
       "      <td>17 September 2018</td>\n",
       "      <td>kathyl0987654321</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antoinette</td>\n",
       "      <td>Good food</td>\n",
       "      <td>The food was good and service was excellent. T...</td>\n",
       "      <td>9 September 2018</td>\n",
       "      <td>374sml</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antoinette</td>\n",
       "      <td>Nougatine sweet crepes</td>\n",
       "      <td>Faded elegant ambience with Victorian cushion ...</td>\n",
       "      <td>2 September 2018</td>\n",
       "      <td>nsl115</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antoinette</td>\n",
       "      <td>Pretty bad service, pretty cakes but something...</td>\n",
       "      <td>We had cake and drinks so that's what we'll re...</td>\n",
       "      <td>20 August 2018</td>\n",
       "      <td>TravelnLive89</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_name                                              title  \\\n",
       "0  Antoinette                                     Superb Service   \n",
       "1  Antoinette                             Perfect high tea place   \n",
       "2  Antoinette                                          Good food   \n",
       "3  Antoinette                             Nougatine sweet crepes   \n",
       "4  Antoinette  Pretty bad service, pretty cakes but something...   \n",
       "\n",
       "                                         review_body        review_date  \\\n",
       "0  The staff @ Mandarin Gallery are very friendly...    18 October 2018   \n",
       "1  Not my first visit and I believe the service h...  17 September 2018   \n",
       "2  The food was good and service was excellent. T...   9 September 2018   \n",
       "3  Faded elegant ambience with Victorian cushion ...   2 September 2018   \n",
       "4  We had cake and drinks so that's what we'll re...     20 August 2018   \n",
       "\n",
       "      reviewer_name bubble_rating  \n",
       "0           blueyme            50  \n",
       "1  kathyl0987654321            50  \n",
       "2            374sml            40  \n",
       "3            nsl115            30  \n",
       "4     TravelnLive89            20  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('\\\\data\\\\Testset.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
